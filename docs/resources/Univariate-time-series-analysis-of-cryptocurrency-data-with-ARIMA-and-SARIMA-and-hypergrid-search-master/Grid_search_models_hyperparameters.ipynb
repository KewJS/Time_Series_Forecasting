{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to grid search ARIMA and SARIMA models hyperparameters\n",
    "\n",
    "<p style=\"text-align: justify\">In this notebook, an exmaple of grid search on ARIMA and SARIMA model parameters is proposed. This notebook is complementary of the 1st one <a href=\"https://github.com/DavidCico/Univariate-time-series-analysis-of-cryptocurrency-data-with-ARIMA-and-SARIMA-and-hypergrid-search/blob/master/Univariate_analysis_classic_methods.ipynb\">Univariate_analysis_classic_methods</a>, and follows the similar procedure in terms of data loading, definition of the testing and training sets, and also for the implementation of the ARIMA and SARIMA models. To avoid repetition, the reader should read this <a href=\"https://github.com/DavidCico/Univariate-time-series-analysis-of-cryptocurrency-data-with-ARIMA-and-SARIMA-and-hypergrid-search/blob/master/Univariate_analysis_classic_methods.ipynb\">notebook</a> first before the current one.\n",
    "\n",
    "\n",
    "<p style=\"text-align: justify\">The ARIMA model for time series analysis and forecasting can be tricky to configure. There are 3 parameters that require estimation by iterative trial and error from reviewing diagnostic plots and using 40-year-old heuristic rules. We can automate the process of evaluating a large number of hyperparameters for the ARIMA model by using a grid search procedure.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The Seasonal Autoregressive Integrated Moving Average, or SARIMA, model is an approach for modeling univariate time series data that may contain trend and seasonal components. It is an effective approach for time series forecasting, although it requires careful analysis and domain expertise in order to configure the seven or more model hyperparameters. An alternative approach to configuring the model that makes use of fast and parallel modern hardware is to grid search a suite of hyperparameter configurations in order to discover what works best. Often, this process can reveal non-intuitive model configurations that result in lower forecast error than those configurations specified through careful analysis.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">In this notebook, you will discover how to develop a framework for grid searching all of the ARIMA and SARIMA model hyperparameters for univariate time series forecasting.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA (and ARIMA) for Time Series Forecasting \n",
    "\n",
    "<p style=\"text-align: justify\">Seasonal Autoregressive Integrated Moving Average, SARIMA or Seasonal ARIMA, is an extension of ARIMA that explicitly supports univariate time series data with a seasonal component.</p>\n",
    "<p style=\"text-align: justify\">It adds three new hyperparameters to specify the autoregression (AR), differencing (I), and moving average (MA) for the seasonal component of the series, as well as an additional parameter for the period of the seasonality.</p>\n",
    "<blockquote><p>A seasonal ARIMA model is formed by including additional seasonal terms in the ARIMA [&#8230;] The seasonal part of the model consists of terms that are very similar to the non-seasonal components of the model, but they involve backshifts of the seasonal period.</p></blockquote>\n",
    "<p style=\"text-align: justify\">&#8212; Page 242, <a href=\"https://amzn.to/2xlJsfV\">Forecasting: principles and practice</a>, 2013.</p>\n",
    "<p style=\"text-align: justify\">Configuring a SARIMA requires selecting hyperparameters for both the trend and seasonal elements of the series.</p>\n",
    "<p style=\"text-align: justify\">There are three trend elements that require configuration.</p>\n",
    "<p style=\"text-align: justify\">They are the same as the ARIMA model; specifically:</p>\n",
    "<ul>\n",
    "<li><strong>p</strong>: Trend autoregression order.</li>\n",
    "<li><strong>d</strong>: Trend difference order.</li>\n",
    "<li><strong>q</strong>: Trend moving average order.</li>\n",
    "</ul>\n",
    "<p style=\"text-align: justify\">There are four seasonal elements that are not part of ARIMA that must be configured; they are:</p>\n",
    "<ul>\n",
    "<li><strong>P</strong>: Seasonal autoregressive order.</li>\n",
    "<li><strong>D</strong>: Seasonal difference order.</li>\n",
    "<li><strong>Q</strong>: Seasonal moving average order.</li>\n",
    "<li><strong>m</strong>: The number of time steps for a single seasonal period.</li>\n",
    "</ul>\n",
    "<p style=\"text-align: justify\">Together, the notation for a SARIMA model is specified as:\n",
    "    \n",
    "    SARIMA(p,d,q)(P,D,Q)m\n",
    "\n",
    "<p style=\"text-align: justify\">The SARIMA model can subsume the ARIMA, ARMA, AR, and MA models via model configuration parameters.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The trend and seasonal hyperparameters of the model can be configured by analyzing autocorrelation and partial autocorrelation plots, and this can take some expertise.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">An alternative approach is to grid search a suite of model configurations and discover which configurations work best for a specific univariate time series.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search framework\n",
    "\n",
    "<p style=\"text-align: justify\">In this section, we will develop a framework for grid searching SARIMA model hyperparameters for a given univariate time series forecasting problem.\n",
    "\n",
    "<p style=\"text-align: justify\">We use the implementation of <a href=\"http://www.statsmodels.org/dev/generated/statsmodels.tsa.arima_model.ARIMA.html\">ARIMA</a> and <a href=\"http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\">SARIMA</a> provided by the statsmodels library.\n",
    "\n",
    "<p style=\"text-align: justify\">This model has hyperparameters that control the nature of the model performed for the series, trend and seasonality, specifically:</p>\n",
    "\n",
    "<ul>\n",
    "<li><strong>order</strong>: A tuple p, d, and q parameters for the modeling of the trend (only parameters required for ARIMA).</li>\n",
    "<li><strong>sesonal_order</strong>: A tuple of P, D, Q, and m parameters for the modeling the seasonality</li>\n",
    "<li><strong>trend</strong>: A parameter for controlling a model of the deterministic trend as one of &#8216;n&#8217;,&#8217;c&#8217;,&#8217;t&#8217;,&#8217;ct&#8217; for no trend, constant, linear, and constant with linear trend, respectively.</li>\n",
    "</ul>\n",
    "<p style=\"text-align: justify\">If you know enough about your problem to specify one or more of these parameters, then you should specify them. If not, you can try grid searching these parameters.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The grid search framework is defined at first in a similar way as in the <a href=\"https://github.com/DavidCico/Univariate-time-series-analysis-of-cryptocurrency-data-with-ARIMA-and-SARIMA-and-hypergrid-search/blob/master/Univariate_analysis_classic_methods.ipynb\">first notebook</a>, concerning the split of the data, the general implementation of the statistic models, as well as the evaluation metric. Here, we repeat of the content at first, to set the framework before introducing the functions for grid search.</p>\n",
    "\n",
    "\n",
    "### Dataset split\n",
    "\n",
    "<p style=\"text-align: justify\">The data in a given dataset will be divided into standard weeks. These are weeks that begin on a Monday and end on a Sunday.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">This is a realistic and useful way for using the chosen framing of the model, where the price for the week ahead can be predicted. It is also helpful with modeling, where models can be used to predict a specific day (e.g. Wednesday) or the entire sequence.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We will split the data into standard weeks, working backwards from the test dataset. This gives 178 weeks of data for the training set and 102 weeks (714 days) for the testing set.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The function <em>split_dataset()</em> below splits the daily data into train and test sets and organizes each into standard weeks. The \"<i>n_test</i>\" argument corresponds to the number of days (714 in this study), to cut the data backwards.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">Specific row offsets are used to split the data using knowledge of the dataset. The split datasets are then organized into weekly data using the NumPy <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html\">split() function</a>.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The <em>to_series()</em> function will also take the multivariate data divided into weekly windows and will return a single univariate time series.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:36.201294Z",
     "start_time": "2020-08-30T08:16:36.194312Z"
    }
   },
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data, n_test):\n",
    "    # split into standard weeks\n",
    "    train, test = data[0:-n_test], data[-n_test:]\n",
    "    # restructure into windows of weekly data\n",
    "    train = np.array(np.split(train, len(train)/7))\n",
    "    test = np.array(np.split(test, len(test)/7))\n",
    "    return train, test\n",
    "\n",
    "# convert windows of weekly multivariate data into a series of closing price\n",
    "def to_series(data):\n",
    "    # extract just the price of XRP from each week\n",
    "    series = [week[:, 0] for week in data]\n",
    "    # flatten into a single series\n",
    "    series = np.array(series).flatten()\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">The Statsmodels library provides multiple ways of developing an AR model, such as using the AR, ARMA, ARIMA, and SARIMAX classes.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We will use the <a href=\"http://www.statsmodels.org/dev/generated/statsmodels.tsa.arima_model.ARIMA.html\">ARIMA implementation</a> as it allows for easy expandability into differencing and moving average. </p>\n",
    "\n",
    "<p style=\"text-align: justify\">The <em>arima_forecast()</em> function defined below implements the procedure for doing a prediction with an ARIMA model for 7 days in a row. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:36.628821Z",
     "start_time": "2020-08-30T08:16:36.622648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arima forecast for weekly prediction\n",
    "def arima_forecast(history, arima_order):\n",
    "    # convert history into a univariate series\n",
    "    series = to_series(history)\n",
    "    # define the model\n",
    "    model = ARIMA(series, order=arima_order)\n",
    "    # fit the model\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make forecast\n",
    "    yhat = model_fit.predict(len(series), len(series)+6)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">The seasonal ARIMA model <a href=\"https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\">SARIMA</a>, can also be implemented in a similar way as the ARIMA model. The <em>Sarima_forecast</em> function below implements the same procedure as above, with the <em>\"config\"</em> argument defining the configuration of the chosen SARIMA model. The seasonal ARIMA model takes more parameters than the regular ARIMA model, to characterize some seasonal trends that might be present inside the dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:36.918319Z",
     "start_time": "2020-08-30T08:16:36.911336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sarima forecast for weekly prediction\n",
    "def Sarima_forecast(history, config):\n",
    "    order, sorder, trend = config\n",
    "    # convert history into a univariate series\n",
    "    series = to_series(history)\n",
    "    # define model\n",
    "    model = SARIMAX(series, order=order, seasonal_order=sorder, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    # fit model\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(series), len(series)+6)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric\n",
    "\n",
    "<p style=\"text-align: justify\">A forecast will be comprised of seven values, one for each day of the week ahead.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The performance metric for this problem will be the <a href=\"https://en.wikipedia.org/wiki/Root-mean-square_deviation\">Root Mean Squared Error (RMSE)</a> for each lead time from day 1 to day 7. In this way, we can see how the chosen algorithms perform on the predictions at a particular day of the week. The cryptocurrency market is quite volatile, and may have a different behaviour depending on the period of the week (weekdays or weekend for instance).</p>\n",
    "<p style=\"text-align: justify\">As a short-cut, it may be useful to summarize the performance of a model using a single score in order to help in model selection. One possible score that could be used would be the RMSE across all forecast days.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The function <i>evaluate_forecasts()</i> below will implement this behavior and return the performance of a model based on multiple seven-day forecasts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:37.210443Z",
     "start_time": "2020-08-30T08:16:37.203722Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk-forward validation\n",
    "\n",
    "<p style=\"text-align: justify\">Models will be evaluated using a scheme called <a href=\"https://en.wikipedia.org/wiki/Walk_forward_optimization\">walk-forward validation</a>.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">This is where a model is required to make a one week prediction, then the actual data for that week is made available to the model so that it can be used as the basis for making a prediction on the subsequent week. This is both realistic for how the model may be used in practice and beneficial to the models allowing them to make use of the best available data.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We can demonstrate this below with separation of input data and output/predicted data.</p>\n",
    "\n",
    "    Input, \t\t\t\t\t\tPredict\n",
    "    [Week1]\t\t\t\t\t\tWeek2\n",
    "    [Week1 + Week2]\t\t\t\tWeek3\n",
    "    [Week1 + Week2 + Week3]\t\tWeek4\n",
    "\n",
    "<p style=\"text-align: justify\">The walk-forward validation approach to evaluating predictive models on this dataset is implement below, named <em>evaluate_model()</em>.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The name of a function is provided for the model as the argument \"<em>model_func</em>\";. This function is responsible for defining the model, fitting the model on the training data, and making a one-week forecast.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The forecasts made by the model are then evaluated against the test dataset using the previously defined <em>evaluate_forecasts()</em> function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:37.534388Z",
     "start_time": "2020-08-30T08:16:37.526411Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_func, train, test, *args):\n",
    "    #history of weekly data\n",
    "    history = [x for x in train]\n",
    "    #walk forward validation\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "    #weekly prediction\n",
    "        y_hat_seq = model_func(history, *args)\n",
    "    #store the preditions\n",
    "        predictions.append(y_hat_seq)\n",
    "    #update history data\n",
    "        history.append(test[i,:])\n",
    "    predictions = np.array(predictions)\n",
    "    # evaluate predictions days for each week\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance of a ARIMA family models\n",
    "\n",
    "<p style=\"text-align: justify\">We can call <em>evaluate_model()</em> repeatedly for a specific model and different lists of model configurations.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">One possible issue is that some combinations of model configurations may not be called for the model and will throw an exception, e.g. specifying some but not all aspects of the seasonal structure in the data.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">Further, some models may also raise warnings on some data, e.g. from the linear algebra libraries called by the statsmodels library.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We can trap exceptions and ignore warnings during the grid search by wrapping all calls to <em>evaluate_model()</em> with a try-except and a block to ignore warnings. We can also add debugging support to disable these protections in the case we want to see what is really going on. Finally, if an error does occur, we can return a None result, otherwise we can print some information about the skill of each model evaluated. This is helpful when a large number of models are evaluated.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The <em>evaluate_arima_family_scores</em> function below implements this and returns a tuple of (key and result), where the key is a string version of the tested model configuration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:37.838542Z",
     "start_time": "2020-08-30T08:16:37.830564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return score on ARIMA family model, for model assessment\n",
    "def evaluate_arima_family_scores(func, name, train, test, order, debug = False):\n",
    "    score = None\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        score, scores, predictions = evaluate_model(func, train, test, order) #evaluate particular model with walk-forward validation\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "            # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                score, scores, predictions = evaluate_model(func, train, test, order)\n",
    "        except:\n",
    "            score = None \n",
    "    # check for an interesting result\n",
    "    if score is not None: # won't print model configurations that returned nothing\n",
    "        print(name + '%s RMSE=%.3f' % (order,score))\n",
    "    return (order, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">Next, we need a loop to test a list of different model configurations.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">This is the main function that drives the grid search process and will call the <em>evaluate_arima_family_scores()</em> function for model configuration of the selected model.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We can dramatically speed up the grid search process by executing this process in parallel. One way to do that is to use the <a href=\"https://pypi.org/project/joblib/\">Joblib library</a>.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We can define a Parallel object with the number of cores to use and set it to the number of scores detected in our hardware.</p>\n",
    "\n",
    "```python\n",
    "executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify\">We can then can then create a list of tasks to execute in parallel, which will be one call to the <em>evaluate_arima_family_scores()</em> function for each model configuration we have.</p>\n",
    "\n",
    "```python\n",
    "tasks = (delayed(evaluate_arima_family_scores)(func, name, order) for order in orders_list)\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify\">Finally, we can use the Parallel object to execute the list of tasks in parallel.</p>\n",
    "\n",
    "```python\n",
    "scores = executor(tasks)\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify\">A non-parallel version of evaluating all model configurations is provided in case we want to debug something.</p>\n",
    "\n",
    "```python\n",
    "scores = [evaluate_arima_family_scores(func, name, order) for order in orders_list]\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify\">The result of evaluating a list of configurations will be a list of tuples, each with a name that summarizes a specific model configuration and the error of the model evaluated with that configuration as either the RMSE or None if there was an error. We can filter out all scores with a None.</p>\n",
    "\n",
    "```python\n",
    "scores = [r for r in scores if r[1] != None]\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify\">We can then sort all tuples in the list by the score in ascending order (best are first), then return this list of scores for review.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The <em>grid_search_arima_family()</em> function below implements this behavior given a univariate time series dataset, a specified model with a name (from a dictionary here), a list of model configurations (list of lists). An optional parallel argument allows the evaluation of models across all cores to be tuned on or off, and is on by default.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:38.133085Z",
     "start_time": "2020-08-30T08:16:38.120120Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid search configs for ARIMA model\n",
    "def grid_search_arima_family(func, name, train, test, orders_list, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "        tasks = (delayed(evaluate_arima_family_scores)(func, name, train, test, order) for order in orders_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [evaluate_arima_family_scores(func, name, train, test, order) for order in orders_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">The only thing left to do is to define a list of model configurations to try for a dataset.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">For the ARIMA model, we create a function <em>arima_orders()</em> that will return a list containing the different orders that will be tested by the <em>grid_search_arima_family()</em> above.\n",
    "\n",
    "<p style=\"text-align: justify\">For the SARIMA model, we can define this generically. The only parameter we may want to specify is the periodicity of the seasonal component in the series, if one exists. By default, we will assume no seasonal component. The <em>Sarima_configs()</em> function below will create a list of model configurations to evaluate.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:16:38.430670Z",
     "start_time": "2020-08-30T08:16:38.418088Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a set of sarima configs to try\n",
    "def arima_orders(p_values, d_values, q_values):\n",
    "    orders = list()\n",
    "    # create config instances\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                orders.append(order)\n",
    "    return orders\n",
    "\n",
    "def Sarima_configs(seasonal=[0]):\n",
    "    configs = list()\n",
    "    # define config lists\n",
    "    p_params = [0, 1, 2]\n",
    "    d_params = [0, 1]\n",
    "    q_params = [0, 1, 2]\n",
    "    t_params = ['n']\n",
    "    P_params = [0, 1, 2]\n",
    "    D_params = [0, 1]\n",
    "    Q_params = [0, 1, 2]\n",
    "    m_params = seasonal\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p,d,q), (P,D,Q,m), t]\n",
    "                                    configs.append(cfg)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">Finally, the grid search procedure can be carried out by looping over the \"<em>models</em>\" dictionary, and the orders (configurations as arguments). The function below implements this procedure and print the 3 best configurations for each model after testing the different hyperparameters.</p>\n",
    "\n",
    "```python\n",
    "for (name, func), arg in zip(models.items(), args):\n",
    "    scores, name = grid_search_arima_family(func, name, train, test, arg, parallel=False)\n",
    "    print('\\n')\n",
    "    print('Top 3 best performing ARIMA models:')\n",
    "    for order, error in scores[:3]:\n",
    "        print(name + str(order), 'RMSE = ' + str(error))\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify\">The script below shows the the full example with the importations of library, and some operations for loading, and pre-processing the data, which have been highlighted in the <a href=\"https://github.com/DavidCico/Univariate-time-series-analysis-of-cryptocurrency-data-with-ARIMA-and-SARIMA-and-hypergrid-search/blob/master/Univariate_analysis_classic_methods.ipynb\">first notebook</a>. The different operations, such as splitting the dataset, defining the models and orders are then executed, before running the search grid for the models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T08:55:21.999716Z",
     "start_time": "2020-08-30T08:16:38.820544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima(0, 0, 0) RMSE=0.567\n",
      "arima(0, 0, 1) RMSE=0.537\n",
      "arima(0, 1, 0) RMSE=0.628\n",
      "arima(0, 1, 1) RMSE=0.628\n",
      "arima(0, 2, 0) RMSE=0.629\n",
      "arima(0, 2, 1) RMSE=0.628\n",
      "arima(1, 0, 0) RMSE=0.195\n",
      "arima(1, 1, 0) RMSE=0.628\n",
      "arima(1, 1, 1) RMSE=0.620\n",
      "arima(1, 2, 0) RMSE=0.629\n",
      "arima(1, 2, 1) RMSE=0.628\n",
      "arima(2, 1, 0) RMSE=0.628\n",
      "arima(2, 1, 1) RMSE=0.626\n",
      "arima(2, 2, 0) RMSE=0.629\n",
      "arima(2, 2, 1) RMSE=0.628\n",
      "arima(3, 0, 0) RMSE=0.199\n",
      "arima(3, 1, 0) RMSE=0.628\n",
      "arima(3, 1, 1) RMSE=0.625\n",
      "arima(3, 2, 0) RMSE=0.629\n",
      "arima(4, 0, 0) RMSE=0.201\n",
      "arima(4, 1, 0) RMSE=0.627\n",
      "arima(4, 1, 1) RMSE=0.624\n",
      "arima(4, 2, 0) RMSE=0.628\n",
      "arima(5, 0, 0) RMSE=0.199\n",
      "arima(5, 1, 0) RMSE=0.626\n",
      "arima(5, 1, 1) RMSE=0.624\n",
      "arima(5, 2, 0) RMSE=0.629\n",
      "arima(5, 2, 1) RMSE=0.629\n",
      "arima(6, 0, 0) RMSE=0.227\n",
      "arima(6, 1, 0) RMSE=0.624\n",
      "arima(6, 1, 1) RMSE=0.620\n",
      "arima(6, 2, 0) RMSE=0.630\n",
      "arima(7, 0, 0) RMSE=0.231\n",
      "arima(7, 1, 0) RMSE=0.621\n",
      "arima(7, 1, 1) RMSE=0.617\n",
      "arima(7, 2, 0) RMSE=0.633\n",
      "arima(7, 2, 1) RMSE=0.633\n",
      "\n",
      "\n",
      "Top 3 best performing ARIMA models:\n",
      "arima(1, 0, 0) RMSE = 0.19512729894548567\n",
      "arima(5, 0, 0) RMSE = 0.19904444278651476\n",
      "arima(3, 0, 0) RMSE = 0.19942534435928927\n",
      "\n",
      "\n",
      "Sarima[(0, 0, 0), (0, 0, 0, 0), 'n'] RMSE=0.629\n",
      "Sarima[(0, 0, 1), (0, 0, 0, 0), 'n'] RMSE=0.595\n",
      "Sarima[(0, 0, 2), (0, 0, 0, 0), 'n'] RMSE=0.571\n",
      "Sarima[(0, 1, 0), (0, 0, 0, 0), 'n'] RMSE=0.196\n",
      "Sarima[(0, 1, 1), (0, 0, 0, 0), 'n'] RMSE=0.197\n",
      "Sarima[(0, 1, 2), (0, 0, 0, 0), 'n'] RMSE=0.201\n",
      "Sarima[(1, 0, 0), (0, 0, 0, 0), 'n'] RMSE=0.247\n",
      "Sarima[(1, 0, 1), (0, 0, 0, 0), 'n'] RMSE=0.248\n",
      "Sarima[(1, 0, 2), (0, 0, 0, 0), 'n'] RMSE=0.251\n",
      "Sarima[(1, 1, 0), (0, 0, 0, 0), 'n'] RMSE=0.197\n",
      "Sarima[(1, 1, 1), (0, 0, 0, 0), 'n'] RMSE=0.265\n",
      "Sarima[(1, 1, 2), (0, 0, 0, 0), 'n'] RMSE=0.269\n",
      "Sarima[(2, 0, 0), (0, 0, 0, 0), 'n'] RMSE=0.247\n",
      "Sarima[(2, 0, 1), (0, 0, 0, 0), 'n'] RMSE=68.674\n",
      "Sarima[(2, 0, 2), (0, 0, 0, 0), 'n'] RMSE=0.252\n",
      "Sarima[(2, 1, 0), (0, 0, 0, 0), 'n'] RMSE=0.201\n",
      "Sarima[(2, 1, 1), (0, 0, 0, 0), 'n'] RMSE=0.265\n",
      "Sarima[(2, 1, 2), (0, 0, 0, 0), 'n'] RMSE=0.259\n",
      "\n",
      "\n",
      "Top 3 best performing ARIMA models:\n",
      "Sarima[(0, 1, 0), (0, 0, 0, 0), 'n'] RMSE = 0.1961476817757037\n",
      "Sarima[(0, 1, 1), (0, 0, 0, 0), 'n'] RMSE = 0.19706578447723153\n",
      "Sarima[(1, 1, 0), (0, 0, 0, 0), 'n'] RMSE = 0.1973957298059591\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "from math import sqrt\n",
    "from scipy.stats import boxcox\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Write name of coin for study (XRP, BTC)\n",
    "    name_coin = 'XRP'\n",
    "\n",
    "    dataset = pd.read_csv(name_coin + '_price.csv', header=0, infer_datetime_format=True, parse_dates=['Date'], index_col=['Date'])\n",
    "\n",
    "    # fill all NaN values with some particular value\n",
    "    dataset.fillna(0, inplace=True)\n",
    "\n",
    "    # make dataset numeric\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # look at the values of the dataset\n",
    "    values = dataset.values\n",
    "\n",
    "    n_test = 714 # Splitting the dataset 714 days before the end\n",
    "\n",
    "    #for n_test in n_tests:\n",
    "    train, test = split_dataset(dataset.values, n_test)\n",
    "\n",
    "    # define the names and functions for the models we wish to evaluate\n",
    "    models = dict()\n",
    "    models['arima'] = arima_forecast\n",
    "    models['Sarima'] = Sarima_forecast\n",
    "    \n",
    "    # values for the ARIMA orders range\n",
    "    p_values = range(0, 8)\n",
    "    d_values = range(0, 3)\n",
    "    q_values = range(0, 2)\n",
    "\n",
    "    orders_arima_list = arima_orders(p_values,d_values,q_values) # function to define ARIMA's orders list\n",
    "    configs_sarima_list = Sarima_configs(seasonal=[0]) # fuction  for SARIMA configurations\n",
    "\n",
    "    args = list() # list of arguments to be called in the loop\n",
    "    args.extend([orders_arima_list, configs_sarima_list])\n",
    "\n",
    "    for (name, func), arg in zip(models.items(), args): # loop on dictionary and configurations at same time\n",
    "        scores, name = grid_search_arima_family(func, name, train, test, arg, parallel=False)\n",
    "        print('\\n')\n",
    "        print('Top 3 best performing ARIMA models:')\n",
    "        for order, error in scores[:3]: # loop ot print best 3 models of the tested function\n",
    "            print(name + str(order), 'RMSE = ' + str(error)) \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">The results show that the best models, for this case with weekly windows of 7 days are the <b>ARIMA(1,0,0)</b> and <b>SARIMA[(0, 1, 0), (0, 0, 0, 0), 'n']</b>. The seasonal component in our case is not obvious considering the short period of time for the windows. However, as seen in the top 3 best SARIMA models, the <b>Q</b> factor for the seasonal moving average plays a role for getting better results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extensions</h2>\n",
    "<p>This section lists some ideas for extending the tutorial that you may wish to explore.</p>\n",
    "<ul>\n",
    "<li><div style=\"text-align: justify\"><strong>Data Transforms</strong>. Update the framework to support configurable data transforms such as normalization and standardization.</div></li>\n",
    "\n",
    "<li><div style=\"text-align: justify\"><strong>Changing rolling window period</strong>. Here, we used a rolling window of 7 days to predict the next 7 days of the cryptocurrency price. Depending on the problem encountered, there might be an optimal window in which the models need to be trained and re-defined for improved results.</div></li>\n",
    "\n",
    "<li><div style=\"text-align: justify\"><strong>Tune Amount of Historical Data</strong>. Update the framework to tune the amount of historical data used to fit the model.</div></li>\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_forecasting",
   "language": "python",
   "name": "ts_forecasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
