{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T07:17:36.860249Z",
     "start_time": "2020-06-07T07:17:28.358806Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "import squarify\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "from IPython.display import display, Markdown, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "from qgrid import show_grid\n",
    "import textwrap as tw\n",
    "import datetime\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa import seasonal\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from scipy import signal\n",
    "import pmdarima as pm\n",
    "\n",
    "from pandas.plotting import lag_plot\n",
    "from pylab import rcParams\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T07:17:42.573021Z",
     "start_time": "2020-06-07T07:17:42.276815Z"
    }
   },
   "outputs": [],
   "source": [
    "# import function\n",
    "import src\n",
    "import src.analysis\n",
    "importlib.reload(src.analysis)\n",
    "from src.analysis import Analysis\n",
    "\n",
    "from src.Config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T07:17:42.754878Z",
     "start_time": "2020-06-07T07:17:42.705038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<a id=\"top\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('<a id=\"top\"></a>'))\n",
    "sections = [\"BIODIESEL_B10\", \"PRIMAX_95\"]\n",
    "\n",
    "sub_sections = [\"Data Summary\", \"Missing Analysis\", \"Time Series Feature Analysis\", \"Modelling Analysis\"]\n",
    "    \n",
    "accordions = OrderedDict()\n",
    "accordions[\"-= Loading =-\"] = widgets.Accordion(children=[widgets.Output() for section in sections])\n",
    "[accordions[\"-= Loading =-\"].set_title(i, section) for i, section in enumerate(sections)]\n",
    "\n",
    "for section in sections:\n",
    "    accordions[section] = widgets.Accordion(children=[widgets.Output() for sub_section in sub_sections])\n",
    "    [accordions[section].set_title(i, sub_section) for i, sub_section in enumerate(sub_sections)]\n",
    "\n",
    "tab_fields = widgets.Tab(children=[accordions[v] for v in accordions])\n",
    "[tab_fields.set_title(i, s) for i, s in enumerate(accordions.keys())];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T07:17:54.460450Z",
     "start_time": "2020-06-07T07:17:54.451475Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6976b930015d4349904bf59793f1a046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Accordion(children=(Output(), Output()), _titles={'0': 'BIODIESEL_B10', '1': 'PRIMAX_95'}), Accoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T07:17:48.529303Z",
     "start_time": "2020-06-07T07:17:48.526281Z"
    }
   },
   "outputs": [],
   "source": [
    "analysis = Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T03:46:33.992064Z",
     "start_time": "2020-06-06T03:44:54.447780Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "section = 'BIODIESEL_B10'\n",
    "\n",
    "with accordions[\"-= Loading =-\"].children[sections.index(section)]:\n",
    "    clear_output()\n",
    "    analysis.get_biodiesel()\n",
    "    \n",
    "#\n",
    "# Data Summary\n",
    "#\n",
    "with accordions[section].children[0]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h2> BioDiesel B10 Data Summary </h2>'))\n",
    "    display(Markdown(r'<h3> 1. Overview from All Stations in BioDiesel B10 </h3>'))\n",
    "    display(analysis.grid_df_display([analysis.descriptive_data(analysis.data['biodiesel_df']), analysis.data_type_analysis(analysis.data['biodiesel_df'])]))\n",
    "    \n",
    "    for district, data in analysis.data['biodiesel_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> Sales For Each Month in <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.weekday_weekend(data, 'Month_Int', 'Prod_Sales'))\n",
    "    \n",
    "    for district in analysis.unique_sorted_values_plus_ALL(analysis.data['biodiesel_df']['District']):\n",
    "        if district != 'ALL':\n",
    "            display(Markdown(r'<h2> {} </h2>'.format(district)))\n",
    "            for col in analysis.data['biodiesel_df'][analysis.data['biodiesel_df']['District'] == district][analysis.vars(['Biodiesel_50'])].columns:\n",
    "                if round(analysis.data['biodiesel_df'][analysis.data['biodiesel_df']['District'] == district][col].isnull().sum() / analysis.data['biodiesel_df'][analysis.data['biodiesel_df']['District'] == district].shape[0], 2) == 1:\n",
    "                    pass\n",
    "                else:   \n",
    "                    display(Markdown(r'<h4> {} </h4>'.format(col)))\n",
    "                    display(analysis.distribution_plot_summary(analysis.data['biodiesel_df'][analysis.data['biodiesel_df']['District'] == district], col, 'Prod_Sales'))   \n",
    "            \n",
    "    display(Markdown('[Home](#top)'))\n",
    "    \n",
    "#\n",
    "# Missing Analysis\n",
    "#\n",
    "with accordions[section].children[1]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h3> 1. Value Available Across All Variables </h3>'))\n",
    "    display(analysis.missingno_barchart(analysis.data['biodiesel_df'], [v for v in analysis.vars(['Biodiesel_50']) if v in analysis.data['biodiesel_df'].columns]))\n",
    "\n",
    "    display(Markdown(r'<h3> {}. {} </h3>'.format(2, \"Input Variables Acquired Across Time in All District\")))\n",
    "    analysis.data['biodiesel_df'][[v for v in analysis.vars(['Biodiesel_50']) if v in analysis.data['biodiesel_df'].columns]].index = pd.to_datetime(analysis.data['biodiesel_df'][[v for v in analysis.vars(['Biodiesel_50']) if v in analysis.data['biodiesel_df'].columns]].index, errors='coerce')\n",
    "    display(analysis.missingno_matrix(analysis.data['biodiesel_df'][[v for v in analysis.vars(['Biodiesel_50']) if v in analysis.data['biodiesel_df'].columns]], 14, 'W'))\n",
    "\n",
    "    display(Markdown(r'<h3> {}. {} </h3>'.format(3, \"Overview on Missing Pattern in <code>Biodisel B10</code> Data\")))\n",
    "    for district, data in analysis.data['missing_pect_biodiesel_50'].groupby('District'):\n",
    "        display(analysis.heatmap_plot(data, district, rotate='vertical'))\n",
    "        \n",
    "    display(Markdown('[Home](#top)'))\n",
    "        \n",
    "#\n",
    "# Time series analysis\n",
    "#\n",
    "with accordions[section].children[2]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h3> Biodiesel Product Sales Across Time with Train-Test Split at: {} </h3>'.format(Config.MODELLING_CONFIG['METRIC_BEST_THRESH'])))\n",
    "    for district, data in analysis.data['biodiesel_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.timeseries_plot(data.reset_index(), 'Date', 'Prod_Sales', datetime.date(2020,3,17), 'Biodiesel Sales at {}'.format(district)))\n",
    "    \n",
    "    display(Markdown(r'<h3> Technical Features Extracted on Time Series Domain </h3>'))\n",
    "    for district, data in analysis.data['biodiesel_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.plot_technical_indicators(data, 'Prod_Sales', data.shape[0]))\n",
    "        display(analysis.histogram_probability_plot(data, 'Prod_Sales', 50, district))\n",
    "        \n",
    "    display(Markdown(r'<h3> Technical Features Extracted on Frequency Domain </h3>'))\n",
    "    for district, data in analysis.data['biodiesel_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.frequency_plot(data, 'Prod_Sales', district))\n",
    "        \n",
    "    display(Markdown('[Home](#top)'))\n",
    "        \n",
    "#\n",
    "# Modelling Analysis\n",
    "#\n",
    "with accordions[section].children[3]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h3> Modelling Analysis on Component of Time Series Data </h3>'))\n",
    "    for district, data in analysis.data['biodiesel_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> Component of Biodiesel Sales at <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.component_plot(data, 'Prod_Sales'))\n",
    "        display(analysis.test_stationarity(data, 'Prod_Sales'))\n",
    "        \n",
    "    display(Markdown(r'<h3> Autocorrelation Plot Analysis </h3>'))\n",
    "    for district, data in analysis.data['biodiesel_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> Number of Lags Dependency Analysis at <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.scatter_lag_plots(data, 8, 'Prod_Sales', district))\n",
    "        display(analysis.autocorrelation_plot(data, 'Prod_Sales'))\n",
    "        display(analysis.partial_autocorrelation_plot(data, 'Prod_Sales'))\n",
    "        \n",
    "    display(Markdown('[Home](#top)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T03:48:02.210718Z",
     "start_time": "2020-06-06T03:46:33.994026Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "section = 'PRIMAX_95'\n",
    "\n",
    "with accordions[\"-= Loading =-\"].children[sections.index(section)]:\n",
    "    clear_output()\n",
    "    analysis.get_primax95()\n",
    "    \n",
    "#\n",
    "# Data Summary\n",
    "#\n",
    "with accordions[section].children[0]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h2> BioDiesel B10 Data Summary </h2>'))\n",
    "    display(Markdown(r'<h3> 1. Overview from All Stations in BioDiesel B10 </h3>'))\n",
    "    display(analysis.grid_df_display([analysis.descriptive_data(analysis.data['primax_95_df']), analysis.data_type_analysis(analysis.data['primax_95_df'])]))\n",
    "    \n",
    "    for district, data in analysis.data['primax_95_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> Sales For Each Month in <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.weekday_weekend(data, 'Month_Int', 'Prod_Sales'))\n",
    "    \n",
    "    for district in analysis.unique_sorted_values_plus_ALL(analysis.data['primax_95_df']['District']):\n",
    "        if district != 'ALL':\n",
    "            display(Markdown(r'<h2> {} </h2>'.format(district)))\n",
    "            for col in analysis.data['primax_95_df'][analysis.data['primax_95_df']['District'] == district][analysis.vars(['Primax_95'])].columns:\n",
    "                if round(analysis.data['primax_95_df'][analysis.data['primax_95_df']['District'] == district][col].isnull().sum() / analysis.data['primax_95_df'][analysis.data['primax_95_df']['District'] == district].shape[0], 2) == 1:\n",
    "                    pass\n",
    "                else:   \n",
    "                    display(Markdown(r'<h4> {} </h4>'.format(col)))\n",
    "                    display(analysis.distribution_plot_summary(analysis.data['primax_95_df'][analysis.data['primax_95_df']['District'] == district], col, 'Prod_Sales'))   \n",
    "    \n",
    "    display(Markdown('[Home](#top)'))\n",
    "    \n",
    "#\n",
    "# Missing Analysis\n",
    "#\n",
    "with accordions[section].children[1]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h3> 1. Value Available Across All Variables </h3>'))\n",
    "    display(analysis.missingno_barchart(analysis.data['primax_95_df'], [v for v in analysis.vars(['Primax_95']) if v in analysis.data['primax_95_df'].columns]))\n",
    "\n",
    "    display(Markdown(r'<h3> {}. {} </h3>'.format(2, \"Input Variables Acquired Across Time in All District\")))\n",
    "    analysis.data['biodiesel_df'][[v for v in analysis.vars(['Biodiesel_50']) if v in analysis.data['primax_95_df'].columns]].index = pd.to_datetime(analysis.data['primax_95_df'][[v for v in analysis.vars(['Primax_95']) if v in analysis.data['biodiesel_df'].columns]].index, errors='coerce')\n",
    "    display(analysis.missingno_matrix(analysis.data['primax_95_df'][[v for v in analysis.vars(['Primax_95']) if v in analysis.data['primax_95_df'].columns]], 14, 'W'))\n",
    "\n",
    "    display(Markdown(r'<h3> {}. {} </h3>'.format(3, \"Overview on Missing Pattern in <code>Primax 95</code> Data\")))\n",
    "    for district, data in analysis.data['missing_pect_primax_95'].groupby('District'):\n",
    "        display(analysis.heatmap_plot(data, district, rotate='vertical'))\n",
    "        \n",
    "    display(Markdown('[Home](#top)'))\n",
    "        \n",
    "#\n",
    "# Time series analysis\n",
    "#\n",
    "with accordions[section].children[2]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h3> Biodiesel Product Sales Across Time with Train-Test Split at: {} </h3>'.format(Config.MODELLING_CONFIG['METRIC_BEST_THRESH'])))\n",
    "    for district, data in analysis.data['primax_95_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.timeseries_plot(data.reset_index(), 'Date', 'Prod_Sales', datetime.date(2020,3,17), 'Primax Sales at {}'.format(district)))\n",
    "    \n",
    "    display(Markdown(r'<h3> Technical Features Extracted on Time Series Domain </h3>'))\n",
    "    for district, data in analysis.data['primax_95_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> {} </h4>'.format(district)))\n",
    "        display(analysis.plot_technical_indicators(data, 'Prod_Sales', data.shape[0]))\n",
    "        display(analysis.histogram_probability_plot(data, 'Prod_Sales', 50, district))\n",
    "        \n",
    "    display(Markdown(r'<h3> Technical Features Extracted on Frequency Domain </h3>'))\n",
    "    for district, data in analysis.data['primax_95_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.frequency_plot(data, 'Prod_Sales', district))\n",
    "        \n",
    "    display(Markdown('[Home](#top)'))\n",
    "        \n",
    "#\n",
    "# Modelling Analysis\n",
    "#\n",
    "with accordions[section].children[3]:\n",
    "    clear_output()\n",
    "    \n",
    "    display(Markdown(r'<h3> Modelling Analysis on Component of Time Series Data </h3>'))\n",
    "    for district, data in analysis.data['primax_95_df'].groupby('District'):\n",
    "        display(Markdown(r'<h4> Component of Primax Sales at <code>{}</code> </h4>'.format(district)))\n",
    "        display(analysis.component_plot(data, 'Prod_Sales'))\n",
    "        display(analysis.test_stationarity(data, 'Prod_Sales'))\n",
    "        \n",
    "    display(Markdown(r'<h3> Autocorrelation Plot Analysis </h3>'))\n",
    "    for district, data in analysis.data['primax_95_df'].groupby('District'):\n",
    "        display(analysis.scatter_lag_plots(data, 8, 'Prod_Sales', district))\n",
    "        display(analysis.autocorrelation_plot(data, 'Prod_Sales'))\n",
    "        display(analysis.partial_autocorrelation_plot(data, 'Prod_Sales'))\n",
    "        \n",
    "    display(Markdown('[Home](#top)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting\n",
    "\n",
    "- Value of p = 2\n",
    "- Value of d\n",
    "- Value of q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.609274Z",
     "start_time": "2020-05-31T09:17:36.905Z"
    }
   },
   "outputs": [],
   "source": [
    "def arima_residual_plot(ar_model, col):\n",
    "    residuals = pd.DataFrame(ar_model.resid)\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "    residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "    plt.show()\n",
    "\n",
    "    # Actual vs Predicted\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    fig = ar_model.plot_predict(dynamic=False, ax=ax)\n",
    "    plt.title('Actual vs Predicted of {}'.format(col), fontsize=18, weight='bold')\n",
    "    plt.xlabel('Date'.format(col), fontsize=15)\n",
    "    plt.ylabel('Values'.format(col), fontsize=15)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.610271Z",
     "start_time": "2020-05-31T09:17:36.912Z"
    }
   },
   "outputs": [],
   "source": [
    "def arima_model_plot(p, d, q, x, test_size):\n",
    "    model = ARIMA(x, order=(p,d,q))\n",
    "\n",
    "    arima_model = model.fit(disp=1)\n",
    "\n",
    "    fc, se, conf = arima_model.forecast(test_size, alpha=0.05)  # 95% conf\n",
    "\n",
    "    # Make as pandas series\n",
    "    fc_series = pd.Series(fc, index=y.index)\n",
    "    lower_series = pd.Series(conf[:, 0], index=y.index)\n",
    "    upper_series = pd.Series(conf[:, 1], index=y.index)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12,5), dpi=100)\n",
    "    plt.plot(x, label='training')\n",
    "    plt.plot(y, label='actual')\n",
    "    plt.plot(fc_series, label='forecast', color='red')\n",
    "\n",
    "    plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                     color='k', alpha=.15)\n",
    "    plt.title('Forecast vs Actuals')\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.show()\n",
    "     \n",
    "    return fc, se, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.611268Z",
     "start_time": "2020-05-31T09:17:36.921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original Series\n",
    "fig, axes = plt.subplots(5, 2)\n",
    "\n",
    "axes[0, 0].plot(temp_df['Prod_Sales']); axes[0, 0].set_title('Original Series')\n",
    "sm.graphics.tsa.plot_acf(temp_df['Prod_Sales'], lags=50, ax=axes[0, 1])\n",
    "\n",
    "# 1st Differencing\n",
    "axes[1, 0].plot(temp_df['Prod_Sales'].diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "sm.graphics.tsa.plot_acf(temp_df['Prod_Sales'].diff().dropna(), ax=axes[1, 1])\n",
    "\n",
    "# 2nd Differencing\n",
    "axes[2, 0].plot(temp_df['Prod_Sales'].diff(periods=2)); axes[2, 0].set_title('2nd Order Differencing')\n",
    "sm.graphics.tsa.plot_acf(temp_df['Prod_Sales'].diff(periods=2).dropna(), ax=axes[2, 1])\n",
    "\n",
    "# 2nd Differencing\n",
    "axes[3, 0].plot(temp_df['Prod_Sales'].diff(periods=3)); axes[3, 0].set_title('2nd Order Differencing')\n",
    "sm.graphics.tsa.plot_acf(temp_df['Prod_Sales'].diff(periods=3).dropna(), ax=axes[3, 1])\n",
    "\n",
    "# 3rd Differencing\n",
    "axes[4, 0].plot(temp_df['Prod_Sales'].diff(periods=4)); axes[4, 0].set_title('2nd Order Differencing')\n",
    "sm.graphics.tsa.plot_acf(temp_df['Prod_Sales'].diff(periods=4).dropna(), ax=axes[4, 1])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.9, wspace=0.15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.612266Z",
     "start_time": "2020-05-31T09:17:36.934Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_df = temp_df.set_index('Date')\n",
    "model_df = temp_df[['Prod_Sales', 'Prod_Sales_diff_1']]\n",
    "model_df = model_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.614261Z",
     "start_time": "2020-05-31T09:17:37.158Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing with order on lag value 2, difference order 1, moving average model 2\n",
    "model = ARIMA(model_df['Prod_Sales'], order=(10,1,2))\n",
    "\n",
    "arima_model = model.fit(disp=0)\n",
    "arima_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.615258Z",
     "start_time": "2020-05-31T09:17:37.180Z"
    }
   },
   "outputs": [],
   "source": [
    "arima_residual_plot(arima_model, 'Prod_Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.617253Z",
     "start_time": "2020-05-31T09:17:37.196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train and test dataset\n",
    "\n",
    "sub_model_df = model_df[['Prod_Sales']]\n",
    "\n",
    "x, y = sub_model_df[0: int(len(sub_model_df) * 0.75)], sub_model_df[int(len(sub_model_df) * 0.75):]\n",
    "print('Training Dataset: %d, Testing Dataset: %d' % (len(x), len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.619248Z",
     "start_time": "2020-05-31T09:17:37.204Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fc, se, conf = arima_model_plot(10, 1, 2, x, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.620245Z",
     "start_time": "2020-05-31T09:17:37.219Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "\n",
    "    return({'mape':mape, 'mae': mae,\n",
    "            'rmse':rmse})\n",
    "\n",
    "forecast_accuracy(fc, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.622240Z",
     "start_time": "2020-05-31T09:17:37.228Z"
    }
   },
   "outputs": [],
   "source": [
    "model = pm.auto_arima(sub_model_df['Prod_Sales'], start_p=3, d=1, start_q=3,\n",
    "                      test='adf',                  # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_d=0, max_q=3,   # maximum p, d, q\n",
    "                      m=5,                         # frequency of series\n",
    "                      seasonal=False,              # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.623237Z",
     "start_time": "2020-05-31T09:17:37.234Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.625231Z",
     "start_time": "2020-05-31T09:17:37.245Z"
    }
   },
   "outputs": [],
   "source": [
    "model.plot_diagnostics(figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.626432Z",
     "start_time": "2020-05-31T09:17:37.470Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.628225Z",
     "start_time": "2020-05-31T09:17:37.488Z"
    }
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.630219Z",
     "start_time": "2020-05-31T09:17:37.502Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range (len(dataset) - time_steps-1):\n",
    "        v = dataset[i: (i + time_steps), 0]\n",
    "        Xs.append(v)\n",
    "        ys.append(dataset[i + time_steps, 0])\n",
    "    return(np.array(Xs), np.array(ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Steps:</b>\n",
    "\n",
    "1. Create the dataset, ensure all data is float.\n",
    "2. Normalize the features.\n",
    "3. Split into training and test sets.\n",
    "4. Convert an array of values into a dataset matrix.\n",
    "5. Reshape into X=t and Y=t+1.\n",
    "6. Reshape input to be 3D (num_samples, num_timesteps, num_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.632212Z",
     "start_time": "2020-05-31T09:17:37.729Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = analysis.data['biodiesel_df']\n",
    "temp_df = temp_df.drop(['Unnamed: 0'], axis=1)\n",
    "temp_df['Date'] = pd.to_datetime(temp_df['Date'])\n",
    "\n",
    "temp_df['Year'] = temp_df['Date'].apply(lambda x: x.year)\n",
    "temp_df['Day'] = temp_df['Date'].apply(lambda x: x.day)\n",
    "\n",
    "temp_df[\"Weekday\"] = temp_df.apply(lambda row: row[\"Date\"].weekday(),axis=1)\n",
    "temp_df[\"Weekday\"] = (temp_df[\"Weekday\"] < 5).astype(int)\n",
    "\n",
    "temp_df = temp_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.634209Z",
     "start_time": "2020-05-31T09:17:37.736Z"
    }
   },
   "outputs": [],
   "source": [
    "# sitiawan_model_df = temp_df[['Prod_Stock', 'Year', 'Month_Int', 'Weekday', 'Prod_Sales']]\n",
    "AREA = 'Tanjung Karang'\n",
    "\n",
    "model_df = temp_df.loc[temp_df['District']==AREA][['Prod_Sales']]\n",
    "\n",
    "train_size = int(len(model_df) * 0.75)\n",
    "test_size = len(model_df) - train_size\n",
    "\n",
    "train, test = model_df.iloc[0:train_size], model_df.iloc[train_size:len(model_df)]\n",
    "print('Training Dataset: {}, Testing Dataset: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.636208Z",
     "start_time": "2020-05-31T09:17:37.742Z"
    }
   },
   "outputs": [],
   "source": [
    "# f_columns = ['Prod_Stock']\n",
    "\n",
    "# f_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# sales_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# f_transformer = f_scaler.fit(train[f_columns].to_numpy())\n",
    "# sales_transformer = sales_scaler.fit(train[['Prod_Sales']])\n",
    "\n",
    "# train.loc[:, f_columns] = f_scaler.transform(train[f_columns].to_numpy())\n",
    "# train['Prod_Sales'] = sales_scaler.transform(train[['Prod_Sales']])\n",
    "\n",
    "# test.loc[:, f_columns] = f_scaler.transform(test[f_columns].to_numpy())\n",
    "# test['Prod_Sales'] = sales_scaler.transform(test[['Prod_Sales']])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.638200Z",
     "start_time": "2020-05-31T09:17:37.751Z"
    }
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 33\n",
    "\n",
    "X_train, y_train = create_dataset(train, time_steps=TIME_STEPS)\n",
    "X_test, y_test = create_dataset(test, time_steps=TIME_STEPS)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.639194Z",
     "start_time": "2020-05-31T09:17:37.802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bidirectional LSTM Model\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(\n",
    "    LSTM(\n",
    "        units=128, \n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    ")\n",
    "    \n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.641190Z",
     "start_time": "2020-05-31T09:17:37.822Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=30, \n",
    "    batch_size=70,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.642188Z",
     "start_time": "2020-05-31T09:17:37.830Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "\n",
    "plt.title('Model Loss Across Time')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.643183Z",
     "start_time": "2020-05-31T09:17:37.841Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.644182Z",
     "start_time": "2020-05-31T09:17:37.867Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Train Mean Absolute Percentage Error', np.mean(np.abs(train_predict[:,0] - y_train[0])/np.abs(y_train[0])))\n",
    "print('Test Mean Absolute Percentage Error', np.mean(np.abs(test_predict[:,0] - y_test[0])/np.abs(y_test[0])))\n",
    "print()\n",
    "print('Train Mean Absolute Error:', mean_absolute_error(y_train[0], train_predict[:,0]))\n",
    "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(y_train[0], train_predict[:,0])))\n",
    "print()\n",
    "print('Test Mean Absolute Error:', mean_absolute_error(y_test[0], test_predict[:,0]))\n",
    "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test[0], test_predict[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.646177Z",
     "start_time": "2020-05-31T09:17:37.882Z"
    }
   },
   "outputs": [],
   "source": [
    "aa=[x for x in range(30)]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(aa, y_train[0][:30], marker='.', label=\"actual\")\n",
    "plt.plot(aa, train_predict[:,0][:30], 'r', label=\"prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine(top=True)\n",
    "plt.subplots_adjust(left=0.07)\n",
    "plt.ylabel('Prod_Sales_Biodiesel', size=15)\n",
    "plt.xlabel('Time Step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Domain\n",
    "\n",
    "**Key idea : Time Series are Sequences**\n",
    "\n",
    "1. Run FFT on input data\n",
    "2. Filter out low-amplitude, high-frequency components\n",
    "3. Forecast on each individual component\n",
    "4. Run inverse of FFT of filtered data\n",
    "\n",
    "**Framework**\n",
    "1. Detector framework\n",
    "2. Data generators\n",
    "3. Simulation framework\n",
    "4. Evaluation functions\n",
    "5. Basic Change Detector\n",
    "6. Monte Carlo Change Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.648170Z",
     "start_time": "2020-05-31T09:17:38.041Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.fftpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform Denoising\n",
    "\n",
    "The Fourier Transform of an 1D signal of $x$ of length $n$ is the following:\n",
    "\n",
    "> $\\mathscr{f}_j = \\sum_{k=0}^{n-1} x_k e^{\\frac{2\\pi i}{n} jk} , ~~\\forall j=0, ... , n-1$\n",
    "\n",
    "The idea is to represent the signal in the complex space, it is roughly the sum of sinusoidal functions. And there is one coefficient per frequency present in the signal.\n",
    "\n",
    "The frequency takes the following values:\n",
    "- $f = \\frac{1}{dn} [0, 1, \\ldots ,   \\frac{n}{2}-1,  -\\frac{n}{2}, \\ldots , -1]$ if $n$ is even\n",
    "- $f =\\frac{1}{dn}  [0, 1, \\ldots,  \\frac{n-1}{2}, -\\frac{n-1}{2}, \\ldots, -1]$ if $n$ is odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.649190Z",
     "start_time": "2020-05-31T09:17:38.177Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_temp_df = temp_df.loc[temp_df['District']=='Sitiawan']\n",
    "sub_temp_df = sub_temp_df[['Prod_Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:22:27.651165Z",
     "start_time": "2020-05-31T09:17:38.184Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "sub_temp_df.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit86cd7af839574b719694da79b128144c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
